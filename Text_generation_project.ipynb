{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_generation_project.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj+o4+GehGHHB1zWJIVj0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddeshnaik/My_Captain_ML/blob/master/Text_generation_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqsBQFx4tYbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing dependance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw1Er7nT5J8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "# loading data and opening our input data in the form of a txt file\n",
        "file = open(r\"/content/frankenstein.txt\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQTej4xj6fTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization\n",
        "#standardization\n",
        "def tokenizer_words(input):\n",
        "    input=input.lower()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input)\n",
        "    filtered = filter(lambda token: token not in stopwords.words(\"english\"), tokens)\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "processed_inputs = tokenizer_words(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPbMmIV-6jr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# chars to numbers\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c,i) for i,c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwNQsUpeKGUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if words to chars or chars to num (?!) has worked?\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"Total number of characters:\", input_len)\n",
        "print(\"Total vocab:\",vocab_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMcNVBg0LxgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQRCstnhL61u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loop through the sequence\n",
        "for i in range(0, input_len - seq_length,1):\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(\"total patterns:\", n_patterns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N96Hz4QpO866",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert input sequence to np array and so on\n",
        "X = np.reshape(x_data, (n_patterns, seq_length,1))\n",
        "X = X/float(vocab_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJbyC8o5Py7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bin9jTWQD5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3zkBmqoSH-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLRdfMLPSlC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving weights\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor= \"loss\", verbose= 1, save_best_only=True, mode=\"min\")\n",
        "desired_callbacks = (checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pexSG-whTOyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model and let it train\n",
        "model.fit(X,y, epochs=100, batch_size=1000, callbacks=desired_callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AKlI59tTk3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recompile model with the saved weights \n",
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GKo1k08b8uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output if the model back into characters\n",
        "num_to_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i-U61hYcYkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random seed to help generate\n",
        "start = np.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed: \")\n",
        "print(\"\\\"\",''.join([num_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybLLQiVzdXR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate the text\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern,(1,len(pattern), 1))\n",
        "    x = x/float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "    seq_in = [num_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1WbMuvMfDdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}